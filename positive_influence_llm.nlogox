<?xml version="1.0" encoding="utf-8"?>
<model version="NetLogo 7.0.3" snapToGrid="true">
  <code><![CDATA[; Positive Influence Model with LLM Conversations
; Based on Smaldino's positive influence opinion dynamics model
; Agents converse via a local Ollama LLM instead of using numeric opinion updates
;
; Requirements:
;   - NetLogo 6.x+ with the Python extension (py)
;   - Python 3.7+ with standard library
;   - Ollama running locally (http://localhost:11434)
;   - A pulled model, e.g.: ollama pull phi3:mini
;
; Alternative small models: tinyllama, qwen2:1.5b, gemma2:2b

extensions [py]

globals [
  last-snippet     ; snippet of the most recent conversation
]

turtles-own [
  opinion          ; float in [-1, 1]
  agent-id         ; integer ID matching the Python memory file
]

;; ── Setup ────────────────────────────────────────────────────────────────────

to setup
  clear-all
  reset-ticks

  ;; Initialize Python and import the helper module
  py:setup py:python
  ;; Add the model's directory to Python's path so it can find llm_helper.py
  ;; We write a temp file to detect the NetLogo working directory from Python
  py:run "import sys, os"
  py:run "import llm_helper"

  ;; Set the topic and model in Python, then initialize agents
  ;; Use py:set to safely pass string values (avoids quoting issues)
  py:set "nl_topic" discussion-topic
  py:set "nl_model" ollama-model
  py:set "nl_num" num-agents
  py:set "nl_memlen" memory-length
  let init-opinions py:runresult "llm_helper.setup_agents(nl_num, nl_topic, nl_model, nl_memlen)"

  ;; Create agents on a grid
  let grid-size ceiling sqrt num-agents
  let agent-counter 0

  create-turtles num-agents [
    set agent-id agent-counter
    set opinion item agent-counter init-opinions

    ;; Place on grid
    let col (agent-counter mod grid-size)
    let row (floor (agent-counter / grid-size))
    let spacing-x (max-pxcor - min-pxcor) / (grid-size + 1)
    let spacing-y (max-pycor - min-pycor) / (grid-size + 1)
    setxy (min-pxcor + spacing-x * (col + 1))
          (min-pycor + spacing-y * (row + 1))

    set shape "circle"
    set size 1.5
    recolor

    set agent-counter agent-counter + 1
  ]

  set last-snippet "(no conversation yet)"
end

;; ── Step (one conversation per tick) ─────────────────────────────────────────

to step
  if count turtles < 2 [ stop ]

  ;; Pick a random agent-A
  let agent-a one-of turtles
  ;; Pick a random partner agent-B (different from A)
  let agent-b one-of other turtles

  let id-a [agent-id] of agent-a
  let id-b [agent-id] of agent-b

  ;; Run the LLM conversation via Python
  ;; Store result in a Python global to avoid dict serialization issues
  py:set "conv_id_a" id-a
  py:set "conv_id_b" id-b
  py:set "conv_tick" ticks
  py:set "conv_memlen" memory-length
  py:run "conv_result = llm_helper.run_conversation(conv_id_a, conv_id_b, conv_tick, conv_memlen)"

  ;; Fetch individual values from the Python result dict
  let new-opinion-a py:runresult "conv_result['opinion_a']"
  let new-opinion-b py:runresult "conv_result['opinion_b']"
  let snippet py:runresult "conv_result['snippet']"

  ;; Update opinions and recolor
  ask agent-a [
    set opinion new-opinion-a
    recolor
  ]
  ask agent-b [
    set opinion new-opinion-b
    recolor
  ]

  ;; Update display
  set last-snippet snippet

  tick
end

;; ── Helpers ──────────────────────────────────────────────────────────────────

to recolor  ;; turtle procedure
  ;; Map opinion [-1, 1] to color on a grayscale: 0 = black, 9.9 = white
  let shade (opinion + 1) / 2 * 9.9
  set color shade
end]]></code>
  <widgets>
    <view x="245" wrappingAllowedX="false" y="35" frameRate="30.0" minPycor="-16" height="405" showTickCounter="true" patchSize="12.0" fontSize="10" wrappingAllowedY="false" width="406" tickCounterLabel="ticks" maxPycor="16" updateMode="1" maxPxcor="16" minPxcor="-16"></view>
    <button x="10" y="10" height="40" disableUntilTicks="false" forever="false" kind="Observer" width="80" display="setup">setup</button>
    <button x="10" y="55" height="40" disableUntilTicks="false" forever="true" kind="Observer" width="180" display="go">step</button>
    <slider x="10" step="1" y="104" max="100" width="180" display="num-agents" height="50" min="4" direction="Horizontal" default="16.0" variable="num-agents"></slider>
    <slider x="10" step="1" y="159" max="20" width="180" display="memory-length" height="50" min="1" direction="Horizontal" default="5.0" variable="memory-length"></slider>
    <plot x="210" autoPlotX="true" yMax="10.0" autoPlotY="true" yAxis="Count" y="478" xMin="-1.0" height="175" legend="false" xMax="1.0" yMin="0.0" width="410" xAxis="Opinion" display="Opinion Distribution">
      <setup>set-plot-x-range -1 1
set-histogram-num-bars 10</setup>
      <update></update>
      <pen interval="0.2" mode="1" display="default" color="-16777216" legend="true">
        <setup></setup>
        <update>histogram [opinion] of turtles</update>
      </pen>
    </plot>
    <monitor x="645" precision="0" y="90" height="60" fontSize="11" width="100" display="Tick">ticks</monitor>
    <monitor x="765" precision="0" y="100" height="60" fontSize="11" width="100" display="Num Agents">count turtles</monitor>
    <input x="725" multiline="false" y="500" height="60" variable="ollama-model" type="string" width="190">qwen2.5:0.5b</input>
    <input x="10" multiline="false" y="218" height="75" variable="discussion-topic" type="string" width="240">AI represents the "Mark of the Beast", representing the end times of humanity.</input>
    <monitor x="655" precision="0" y="155" height="70" fontSize="11" width="450" display="Last Conversation">last-snippet</monitor>
    <button x="95" y="10" height="40" disableUntilTicks="false" forever="false" kind="Observer" width="95" display="go-once">step</button>
    <plot x="655" autoPlotX="true" yMax="1.0" autoPlotY="false" yAxis="opinions" y="235" xMin="0.0" height="250" legend="false" xMax="10.0" yMin="-1.0" width="400" xAxis="time" display="Agent opinions over time">
      <setup></setup>
      <update></update>
      <pen interval="1.0" mode="2" display="default" color="-14730904" legend="true">
        <setup></setup>
        <update>if (ticks mod 100 = 0) [ask turtles [
plotxy ticks opinion
]
]</update>
      </pen>
    </plot>
  </widgets>
  <info>## WHAT IS IT?

This model recreates Smaldino's positive influence opinion dynamics model, replacing the simple numeric opinion update rule with actual natural language conversations between agents powered by a local Ollama LLM.

Each agent maintains a memory file of past conversations and all interactions are logged to a master transcript. After each conversation, the LLM extracts a numeric opinion score in [-1, 1] for visualization.

## HOW IT WORKS

**Setup:** Creates N agents, each assigned a random initial opinion stance on the configured topic. Agent memories are stored as text files in `agent_memories/`.

**Each tick:** One random agent initiates a 3-turn conversation with a random partner via the Ollama LLM. The conversation is informed by both agents' current stances and recent memory. After the conversation, a separate LLM call extracts updated opinion scores for both agents.

**Visualization:** Agents are colored on a black-to-white scale based on their opinion (-1 = black/against, +1 = white/in favor).

## HOW TO USE IT

### Prerequisites
1. Install [Ollama](https://ollama.ai)
2. Pull a small model: `ollama pull phi3:mini`
3. Start Ollama: `ollama serve`
4. NetLogo 6.x+ with the Python extension

### Running
1. Set the **discussion-topic** (the issue agents will debate)
2. Set the **ollama-model** (default: phi3:mini)
3. Set **num-agents** (keep low, e.g. 25, since each tick requires LLM calls)
4. Click **setup** to initialize agents
5. Click **go-once** for a single conversation, or **go** for continuous

### Parameters
- **num-agents**: Number of agents (4-100, default 25)
- **memory-length**: How many past conversations to include in prompts (default 5)
- **discussion-topic**: The topic agents discuss
- **ollama-model**: Which Ollama model to use (phi3:mini, tinyllama, qwen2:1.5b, gemma2:2b)

## THINGS TO NOTICE

- Opinions tend to converge over time, matching the original positive influence model
- The histogram shows the distribution of opinions shifting
- Check `transcript.txt` for full conversation logs
- Check `agent_memories/` for individual agent histories

## CREDITS AND REFERENCES

Based on Smaldino's positive influence model. LLM integration by Claude.</info>
  <turtleShapes>
    <shape name="default" rotatable="true" editableColorIndex="0">
      <polygon color="-1920102913" filled="true" marked="true">
        <point x="150" y="5"></point>
        <point x="40" y="250"></point>
        <point x="150" y="205"></point>
        <point x="260" y="250"></point>
      </polygon>
    </shape>
    <shape name="circle" rotatable="false" editableColorIndex="0">
      <circle x="0" y="0" marked="true" color="-1920102913" diameter="300" filled="true"></circle>
    </shape>
  </turtleShapes>
  <linkShapes>
    <shape name="default" curviness="0.0">
      <lines>
        <line x="-0.2" visible="false">
          <dash value="0.0"></dash>
          <dash value="1.0"></dash>
        </line>
        <line x="0.0" visible="true">
          <dash value="1.0"></dash>
          <dash value="0.0"></dash>
        </line>
        <line x="0.2" visible="false">
          <dash value="0.0"></dash>
          <dash value="1.0"></dash>
        </line>
      </lines>
      <indicator>
        <shape name="link direction" rotatable="true" editableColorIndex="0">
          <line endX="90" startY="150" marked="true" color="-1920102913" endY="180" startX="150"></line>
          <line endX="210" startY="150" marked="true" color="-1920102913" endY="180" startX="150"></line>
        </shape>
      </indicator>
    </shape>
  </linkShapes>
  <previewCommands>setup repeat 75 [ go ]</previewCommands>
</model>
